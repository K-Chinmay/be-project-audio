{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import librosa.display\n",
    "from skimage.color import gray2rgb\n",
    "from skimage.transform import resize\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Function to extract Mel spectrograms from audio files\n",
    "def extract_mel_spectrogram(audio_file, n_mels=64, hop_length=512):\n",
    "    y, sr = librosa.load(audio_file, sr=None)\n",
    "    mel_spectrogram = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=n_mels, hop_length=hop_length)\n",
    "    mel_spectrogram = librosa.power_to_db(mel_spectrogram, ref=np.max)\n",
    "    return mel_spectrogram\n",
    "\n",
    "# Path to your bird audio dataset\n",
    "dataset_path = \"birds_audio_dataset/\"\n",
    "\n",
    "# List of supported audio file extensions\n",
    "supported_extensions = ['.wav', '.mp3', '.mp4']\n",
    "\n",
    "# Load the trained MobileNet model\n",
    "model = load_model(\"mobilenet_model.h5\", compile=False)\n",
    "\n",
    "# Compile the model with eager execution\n",
    "model.compile(run_eagerly=True)\n",
    "\n",
    "# Preprocessing function for test data\n",
    "def preprocess_test_data(dataset_path, supported_extensions):\n",
    "    test_data = []\n",
    "    labels = []\n",
    "\n",
    "    for class_name in os.listdir(dataset_path):\n",
    "        class_path = os.path.join(dataset_path, class_name)\n",
    "        if os.path.isdir(class_path):\n",
    "            for audio_file in os.listdir(class_path):\n",
    "                file_extension = os.path.splitext(audio_file)[1].lower()  # Get the file extension\n",
    "                if file_extension in supported_extensions:\n",
    "                    audio_path = os.path.join(class_path, audio_file)\n",
    "                    try:\n",
    "                        mel_spec = extract_mel_spectrogram(audio_path)\n",
    "                       # Resize spectrogram to match MobileNetV2 input size\n",
    "                        resized_spec = resize(mel_spec, (64, 64), anti_aliasing=True)\n",
    "                        # Convert grayscale spectrogram to RGB\n",
    "                        rgb_spec = gray2rgb(resized_spec)\n",
    "                        test_data.append(rgb_spec)\n",
    "                        labels.append(class_name)\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error processing {audio_path}: {e}\")\n",
    "\n",
    "    test_data = np.array(test_data)\n",
    "    labels = np.array(labels)\n",
    "    return test_data, labels\n",
    "\n",
    "# Preprocess the test data\n",
    "X_test, y_test = preprocess_test_data(dataset_path, supported_extensions)\n",
    "\n",
    "# Evaluate the model\n",
    "predictions = model.predict(X_test)\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Decode labels\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_test)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = np.mean(predicted_labels == y_test_encoded)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
